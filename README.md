# ğŸ™ï¸ Clone Voice Adapter

<div align="center">

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YangNobody12/clone-voice-adapter/blob/main/fine_tune_clone_voice.ipynb)

**Fine-tune TTS à¹‚à¸¡à¹€à¸”à¸¥à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™à¹€à¸ªà¸µà¸¢à¸‡à¸‚à¸­à¸‡à¸„à¸¸à¸“à¹€à¸­à¸‡ à¸”à¹‰à¸§à¸¢ LoRA + Unsloth**

</div>

---

## âœ¨ Features

- ğŸ¤ **à¸šà¸±à¸™à¸—à¸¶à¸à¹€à¸ªà¸µà¸¢à¸‡** â†’ à¸•à¸±à¸”à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¹€à¸›à¹‡à¸™ 11-15 à¸§à¸´à¸™à¸²à¸—à¸µ à¸¥à¸šà¹€à¸ªà¸µà¸¢à¸‡à¹€à¸‡à¸µà¸¢à¸š
- ğŸ—£ï¸ **Typhoon ASR** â†’ Speech-to-Text à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸”à¹‰à¸§à¸¢ API
- ğŸ“Š **à¸ªà¸£à¹‰à¸²à¸‡ Dataset** â†’ Format LJSpeech à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´
- ğŸ‹ï¸ **Train LoRA** â†’ Fine-tune à¸”à¹‰à¸§à¸¢ Unsloth à¸šà¸™ T4 GPU à¸Ÿà¸£à¸µ
- ğŸ”Š **Inference** â†’ à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸ªà¸µà¸¢à¸‡à¸ˆà¸²à¸ Text à¸”à¹‰à¸§à¸¢à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¹€à¸—à¸£à¸™

---

## ğŸš€ Quick Start

### Google Colab (à¹à¸™à¸°à¸™à¸³!)
```
à¸à¸”à¸›à¸¸à¹ˆà¸¡ "Open in Colab" à¸”à¹‰à¸²à¸™à¸šà¸™ â†’ Run all cells
```

### Local
```bash
pip install -r requirements.txt
python app_gui.py
```

> âš ï¸ **à¸•à¹‰à¸­à¸‡à¸à¸²à¸£:** Python 3.10+, CUDA GPU, FFmpeg

---

## ğŸ“‹ Pipeline

```
1. à¸šà¸±à¸™à¸—à¸¶à¸à¹€à¸ªà¸µà¸¢à¸‡ (1-5 à¸™à¸²à¸—à¸µ)
      â†“
2. à¸•à¸±à¸”à¹€à¸›à¹‡à¸™ segments 11-15s + à¸¥à¸šà¹€à¸ªà¸µà¸¢à¸‡à¹€à¸‡à¸µà¸¢à¸š
      â†“
3. Typhoon STT â†’ transcribe à¹€à¸›à¹‡à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡
      â†“
4. à¸ªà¸£à¹‰à¸²à¸‡ metadata.csv (LJSpeech format)
      â†“
5. Train LoRA (60-360 steps)
      â†“
6. Inference â†’ à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸ªà¸µà¸¢à¸‡à¸ˆà¸²à¸ text
```

---

## ğŸ–¥ï¸ GUI Tabs

| Tab | à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆ |
|-----|---------|
| **1. à¸šà¸±à¸™à¸—à¸¶à¸ & à¸ªà¸£à¹‰à¸²à¸‡ Dataset** | Record/Upload â†’ à¸•à¸±à¸” â†’ STT â†’ metadata.csv |
| **2. Train Model** | Fine-tune LoRA à¸”à¹‰à¸§à¸¢ config à¸—à¸µà¹ˆà¸à¸³à¸«à¸™à¸” |
| **3. Inference** | Text-to-Speech à¸”à¹‰à¸§à¸¢à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¹€à¸—à¸£à¸™ |

---

## âš™ï¸ Configuration

à¹à¸à¹‰à¹„à¸‚à¹„à¸”à¹‰à¹ƒà¸™ `config.py`:

```python
# Model
model_name = "unsloth/orpheus-3b-0.1-ft"  # à¸«à¸£à¸·à¸­ custom model
max_seq_length = 2048
r = 64                    # LoRA rank

# Training
max_steps = 360           # à¸ˆà¸³à¸™à¸§à¸™ training steps
learning_rate = 2e-4
```

---

## ğŸ“ Output Structure

```
dataset/
â”œâ”€â”€ metadata.csv         # wavs/xxx.wav|à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡
â””â”€â”€ wavs/
    â”œâ”€â”€ audio_001.wav
    â””â”€â”€ audio_002.wav

outputs/
â””â”€â”€ checkpoint-360/      # LoRA weights
```

---

## ğŸ”§ Requirements

- **GPU:** NVIDIA with CUDA (T4, V100, A100, RTX)
- **VRAM:** 16GB+ recommended
- **Python:** 3.10+
- **FFmpeg:** à¸ªà¸³à¸«à¸£à¸±à¸š audio processing

```bash
# Windows
choco install ffmpeg

# Linux
sudo apt install ffmpeg
```

---

## ğŸ“š Files

| File | Description |
|------|-------------|
| `app_gui.py` | Main Gradio GUI |
| `audio_processor.py` | à¸•à¸±à¸” audio, à¸¥à¸šà¹€à¸ªà¸µà¸¢à¸‡à¹€à¸‡à¸µà¸¢à¸š |
| `typhoon_stt.py` | Typhoon ASR API |
| `dataset_prep.py` | à¹€à¸•à¸£à¸µà¸¢à¸¡ dataset à¸ªà¸³à¸«à¸£à¸±à¸š train |
| `train.py` | Training script |
| `inference.py` | Text-to-Speech inference |
| `config.py` | Model & training config |

---

## ğŸ™ Credits

- [Unsloth](https://github.com/unslothai/unsloth) - Fast LoRA fine-tuning
- [Orpheus-3B](https://huggingface.co/canopylabs/orpheus-3b) - Base TTS model
- [SNAC](https://github.com/hubertsiuzdak/snac) - Audio codec
- [Typhoon](https://opentyphoon.ai) - Thai ASR API

---

## ğŸ“„ License

MIT License